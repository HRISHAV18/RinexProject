# -*- coding: utf-8 -*-
"""Major project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gktH_r_P1Sd2nGnee88ICkyke623YA_w
"""

#30th AUGUST , 2022

#MACHINE LEARNING - SUPERVISED LEARNING -REGRESSION - LINEAR REGRESSION
# Linear Regression
#Dataset - Price Prediction
#Dataset - https://raw.githubusercontent.com/HRISHAV18/RinexProject/main/scrap%20price.csv

#1.Take the data and create dataframe
import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/HRISHAV18/RinexProject/main/scrap%20price.csv')
df

df.info()

df.shape

df.size

#VISUALISATION
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize = (15,15))
plt.xticks( fontsize=15)
plt.yticks( fontsize=15)
sns.distplot(df['price']) #distribution plot

#Now we have to remove or drop the ID and Symbling column
df = df.drop(columns=['ID','symboling'])

df.isna().sum()

df

df.info()

#We want to consider only the numeric data
#So we will create a new dataframe with only numeric data
df_numeric = df.select_dtypes(include = ['float64','int64'])
df_numeric

df_numeric.info()

#divide the data into i/p and o/p
#output - price 
#input - All the columns except the price column

x = df_numeric.iloc[:,0:13].values
x

y = df_numeric.iloc[:,13].values
y

#5.TRAIN and TEST VARIABLES
#sklearn.model_selection - package , train_test_split - library
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0)

print(x.shape) # 205 rows and 13 cols
print(x_train.shape) #153 rows and 13 cols (75%)
print(x_test.shape) # 52 rows and 13 cols (25%)

print(y.shape) # 205 rows and 1 col
print(y_train.shape) # 153 rows and 1 cols(75 %)
print(y_test.shape) #52rows and 1 col(25%)

#SCALING or NORMALISATION -DONE ONLY FOR INPUTS
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

#7.RUN a CLASSIFIER/REGRESSOR/CLUSTERER
from sklearn.linear_model import LinearRegression
model = LinearRegression()

#8.MODEL FITTING
model.fit(x_train,y_train)

#9.PREDICT THE OUTPUT
y_pred = model.predict(x_test)#By taking the input testing data , we predict the output
y_pred #PREDICTED VALUES

y_test #ACTUAL VALUES

#these are scaled/normalised values
print(x_train[10])

#INDIVIDUAL PREDICTION
model.predict([x_train[10]])# price of the car

#INDIVIDUAL PREDICTION
model.predict([x_train[5]])

plt.scatter(y_test,y_pred);
plt.xlabel('Actual');
plt.ylabel('Predicted');

sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');
plt.xlabel('price');
plt.ylabel('Predicted');

pred_df_numeric=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})

pred_df_numeric

# FOR HEROKU APP DEPLOY
# INPUT IS CAR'S NAME
# OUTPUT IS FUELTYPES

df_object = df.select_dtypes(include = ['object'])
df_object

#I just want to know how many fueltypes  are there
df['fueltypes'].value_counts()

#VISUALISATION
df['fueltypes'].value_counts().plot(kind = 'bar')

#4.divide the data into input and output
x = df.iloc[:,0].values
y = df.iloc[:,1].values
print(x)
print(y)

#5.train_test_split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0)

#6.Apply TF-IDF vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vect = TfidfVectorizer()
x_train_v = vect.fit_transform(x_train)
x_test_v = vect.transform(x_test)

#7.Apply CLASSIFIER
from sklearn.svm import SVC
model = SVC()

#8.model fitting
model.fit(x_train_v,y_train)

#9.Predictor variable/predict the output
y_pred = model.predict(x_test_v)
y_pred #Predicted values

y_test # actual values

#Accuracy
from sklearn.metrics import accuracy_score
accuracy_score(y_pred,y_test)*100

#Evaluating a specific name (1st)
a = df['name'][10]
a

a = vect.transform([a])
model.predict(a)

#Evaluating a specific name (2nd)
b = df['name'][12] #12th index from the message column
b

b = vect.transform([b])
model.predict(b)

#Evaluating by taking custom texts
c = 'audi'
c

c = vect.transform([c])
model.predict(c)

#If ever I have to deploy my model,I will have to perform pipelining

#Pipelining
from sklearn.pipeline import make_pipeline
text_model = make_pipeline(TfidfVectorizer(),SVC())
text_model.fit(x_train,y_train)

#predictor varibale
y_pred1 = text_model.predict(x_test)
y_pred1 # these are predicted outputs for pipelined model

y_test #Actual output

#To check the accuracy of the pipelined model
accuracy_score(y_pred1,y_test)*100

#Individual Prediction/Evaluation of a specific name
a1 = df['name'][2]
a1

text_model.predict([a1])

#JOBLIB  - 2 different types - 1.Dump and 2.Load
import joblib
joblib.dump(text_model,'gas-diesel')
#We are creating a newfile called gas-diesel and we are dumping our pipelined model
#inside it.

